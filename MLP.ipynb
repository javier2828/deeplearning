{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ix5dQS2rUMlu"
   },
   "source": [
    "#EECS 442/504 PS4: Backpropagation\n",
    "\n",
    "__Please provide the following information__\n",
    "(e.g. Andrew Owens, ahowens):\n",
    "\n",
    "[Javier] [Salazar Cavazos], [61070296]\n",
    "\n",
    "__Important__: after you download the .ipynb file, please name it as __\"PS\\<this_ps_number\\>_\\<your_uniqname\\>.ipynb\"__ before you submit it to canvas. Example: adam_01101100.ipynb.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W_Cst4k4tuBc"
   },
   "source": [
    "# Starting\n",
    "\n",
    "Run the following code to import the modules you'll need. After your finish the assignment, remember to run all cells and save the note book to your local machine as a .ipynb file for Canvas submission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "SHumIO-xt57H"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.0%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./cifar-10-python.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "57.6%IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./cifar-10-python.tar.gz to .\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import math\n",
    "from torchvision.datasets import CIFAR10\n",
    "download = not os.path.isdir('cifar-10-batches-py')\n",
    "dset_train = CIFAR10(root='.', download=download)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "87aUvJJ52FeY"
   },
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4WpKb7SvKR6W"
   },
   "source": [
    "# Problem 4.1 Understanding Backpropagation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fy-7c_kJKUCd"
   },
   "source": [
    "# 4.1 (b)  \n",
    "Implement the code for forward and backward pass of computation graph in (a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "yojDcdIzXcNB"
   },
   "outputs": [],
   "source": [
    "def f_1(x0, x1, x2, w0, w1, w2, w3):\n",
    "    \"\"\"\n",
    "    Computes the forward and backward pass through the computational graph \n",
    "    of (a)\n",
    "\n",
    "    Inputs:\n",
    "    - x0, x1, x2, w0, w1, w2, w3: Python floats\n",
    "\n",
    "    Returns a tuple of:\n",
    "    - L: The output of the graph\n",
    "    - grads: A tuple (grad_x0, grad_x1, grad_x2, grad_w0, grad_w1, grad_w2, \n",
    "      grad_w3)\n",
    "    giving the derivative of the output L with respect to each input.\n",
    "    \"\"\"\n",
    "    ###########################################################################\n",
    "    # TODO: Implement the forward pass for the computational graph for (a) and#\n",
    "    # store the output of this graph as L                                     #\n",
    "    ###########################################################################\n",
    "    p0 = x0*w0\n",
    "    p1 = x1*w1\n",
    "    p22 = (x2)**-1\n",
    "    p2 = p22*w2\n",
    "    p01 = p0+p1\n",
    "    p012 = p01-p2\n",
    "    p0123 = w3+p012\n",
    "    pe = -1*p0123\n",
    "    pe2 = np.exp(pe)\n",
    "    pl = pe2+1\n",
    "    L = (pl)**-1\n",
    "    \n",
    "    ###########################################################################\n",
    "    #                              END OF YOUR CODE                           #\n",
    "    ###########################################################################\n",
    "    \n",
    "    ###########################################################################\n",
    "    # TODO: Implement the backward pass for the computational graph for (a)   #\n",
    "    # Store the gradients for each input                                      #\n",
    "    ###########################################################################\n",
    "    grad_L = 1\n",
    "    grad_pl = grad_L * -1/(pl)**2\n",
    "    grad_pe2 = grad_pl * 1\n",
    "    grad_pe = grad_pe2 * np.exp(pe)\n",
    "    grad_p0123 = grad_pe * -1\n",
    "    grad_w3 = grad_p0123 * 1\n",
    "    grad_p012 = grad_p0123 * 1\n",
    "    grad_p2 = grad_p012 *-1\n",
    "    grad_w2 = grad_p2 * p22\n",
    "    grad_p22 = grad_p2 * w2\n",
    "    grad_x2 = grad_p22 * -1/(x2)**2\n",
    "    grad_p01 = grad_p012 * 1\n",
    "    grad_p1 = grad_p01 * 1\n",
    "    grad_w1 = grad_p1 * x1\n",
    "    grad_x1 = grad_p1 * w1\n",
    "    grad_p0 = grad_p01 * 1\n",
    "    grad_w0 = grad_p0 * x0\n",
    "    grad_x0 = grad_p0 * w0\n",
    "\n",
    "\n",
    "    ###########################################################################\n",
    "    #                              END OF YOUR CODE                           #\n",
    "    ###########################################################################\n",
    "\n",
    "    grads = (grad_x0, grad_x1, grad_x2, grad_w0, grad_w1, grad_w2, grad_w3)\n",
    "    return L, grads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CdquTNqGKYcc"
   },
   "source": [
    "# 4.1 (c)  \n",
    "Implement the code for forward and backward pass of computation graph in (c)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "o55wTks0KaPC"
   },
   "outputs": [],
   "source": [
    "def f_2(w, x, y, z):\n",
    "    \"\"\"\n",
    "    Computes the forward and backward pass through the computational graph \n",
    "    of (c)\n",
    "\n",
    "    Inputs:\n",
    "    - w, x, y, z: Python floats\n",
    "\n",
    "    Returns a tuple of:\n",
    "    - L: The output of the graph\n",
    "    - grads: A tuple (grad_w, grad_x, grad_y, grad_z)\n",
    "    giving the derivative of the output L with respect to each input.\n",
    "    \"\"\"\n",
    "    ###########################################################################\n",
    "    # TODO: Implement the forward pass for the computational graph for (c) and#\n",
    "    # store the output of this graph as L                                     #\n",
    "    ###########################################################################\n",
    "    a = w**-1\n",
    "    b = x**-1\n",
    "    e = a**b\n",
    "    c = np.exp(y)\n",
    "    d = np.exp(z)\n",
    "    c1 = c\n",
    "    c2 = c\n",
    "    d1 = d\n",
    "    d2 = d\n",
    "    p = d1 * c1\n",
    "    p1 = p\n",
    "    p2 = p\n",
    "    f = p1 + c2\n",
    "    g = d2/p2\n",
    "    m = e-f\n",
    "    n = m/g\n",
    "    L = n**2\n",
    "    \n",
    "    ###########################################################################\n",
    "    #                              END OF YOUR CODE                           #\n",
    "    ###########################################################################\n",
    "\n",
    "    ###########################################################################\n",
    "    # TODO: Implement the backward pass for the computational graph for (c)   #\n",
    "    # Store the gradients for each input                                      #\n",
    "    ###########################################################################\n",
    "    grad_L = 1\n",
    "    grad_n = grad_L * 2*n\n",
    "    grad_g = grad_n * -m/(g**2)\n",
    "    grad_m = grad_n * 1/g\n",
    "    grad_e = grad_m * 1\n",
    "    grad_b = grad_e * (a**b)*np.log(a)\n",
    "    grad_x = grad_b * -1\n",
    "    grad_a = grad_e * a**(b-1) *b\n",
    "    grad_w = grad_a * -1/(w**2)\n",
    "    grad_f = grad_m * -1\n",
    "    grad_c2 = grad_f * 1\n",
    "    grad_p1 = grad_f * 1\n",
    "    grad_p2 = grad_g * -d2/(p2**2)\n",
    "    grad_d2 = grad_g * 1/p2\n",
    "    grad_p = grad_p1 + grad_p2\n",
    "    grad_d1 = grad_p * c1\n",
    "    grad_c1 = grad_p * d1\n",
    "    grad_d = grad_d1 + grad_d2\n",
    "    grad_c = grad_c1 + grad_c2\n",
    "    grad_z = grad_d * np.exp(z)\n",
    "    grad_y = grad_c * np.exp(y)\n",
    "    \n",
    "\n",
    "   \n",
    "    ###########################################################################\n",
    "    #                              END OF YOUR CODE                           #\n",
    "    ###########################################################################\n",
    "\n",
    "    grads = (grad_w, grad_x, grad_y, grad_z)\n",
    "    return L, grads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "apEPzDNtK0MC"
   },
   "source": [
    "# Problem 4.2 Softmax Classifier with Two Layer Neural Network\n",
    "In this problem you will develop a two Layer neural network with fully-connected layers to perform classification, and test it out on the CIFAR-10 dataset.\n",
    "\n",
    "We train the network with a softmax loss function on the weight matrices. The network uses a ReLU nonlinearity after the first fully connected layer. In other words, the network has the following architecture:\n",
    "\n",
    "input - fully connected layer - ReLU - fully connected layer - softmax\n",
    "\n",
    "The outputs of the second fully-connected layer are the scores for each class.\n",
    "\n",
    "You cannot use any deep learning libraries such as PyTorch in this part."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SXfumCQ21JoK"
   },
   "source": [
    "# 4.2 (a) Layers\n",
    "In this problem, implement fully connected layer, relu and softmax. Filling in all TODOs in skeleton codes will be sufficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "id": "Q-ljfgMv9PHx"
   },
   "outputs": [],
   "source": [
    "def fc_forward(X, W, b):\n",
    "    \"\"\"\n",
    "    Computes the forward pass for a fully-connected layer.\n",
    "    \n",
    "    The input X has shape (N, Din) and contains a minibatch of N\n",
    "    examples, where each example x[i] has shape (Din,).\n",
    "    \n",
    "    Inputs:\n",
    "    - X: A numpy array containing input data, of shape (N, Din)\n",
    "    - W: A numpy array of weights, of shape (Din, Dout)\n",
    "    - b: A numpy array of biases, of shape (Dout,)\n",
    "    \n",
    "    Returns a tuple of:\n",
    "    - out: output, of shape (N, Dout)\n",
    "    - cache: (X, W, b)\n",
    "    \"\"\"\n",
    "    ###########################################################################\n",
    "    # TODO: Implement the forward pass. Store the result in out.              #\n",
    "    ###########################################################################\n",
    "    out = (X @ W) + b[None,:]\n",
    "\n",
    "    ###########################################################################\n",
    "    #                             END OF YOUR CODE                            #\n",
    "    ###########################################################################\n",
    "    cache = (X, W, b)\n",
    "    return out, cache\n",
    "\n",
    "\n",
    "def fc_backward(dout, cache):\n",
    "    \"\"\"\n",
    "    Computes the backward pass for a fully_connected layer.\n",
    "    \n",
    "    Inputs:\n",
    "    - dout: Upstream derivative, of shape (N, Dout)\n",
    "    - cache: returned by your forward function. Tuple of:\n",
    "      - X: Input data, of shape (N, Din)\n",
    "      - W: Weights, of shape (Din, Dout)\n",
    "      - b: Biases, of shape (Dout,)\n",
    "      \n",
    "    Returns a tuple of:\n",
    "    - dX: Gradient with respect to X, of shape (N, Din)\n",
    "    - dW: Gradient with respect to W, of shape (Din, Dout)\n",
    "    - db: Gradient with respect to b, of shape (Dout,)\n",
    "    \"\"\"\n",
    "    X, W, b = cache\n",
    "    dX, dW, db = None, None, None\n",
    "    ###########################################################################\n",
    "    # TODO: Implement the affine backward pass.                               #\n",
    "    ###########################################################################\n",
    "    dX = dout @ W.T\n",
    "    dW = X.T @ dout\n",
    "    db = dout.T @ np.ones(X.shape[0])\n",
    "\n",
    "\n",
    "\n",
    "    ###########################################################################\n",
    "    #                             END OF YOUR CODE                            #\n",
    "    ###########################################################################\n",
    "    return dX, dW, db\n",
    "\n",
    "def relu_forward(x):\n",
    "    \"\"\"\n",
    "    Computes the forward pass for a layer of rectified linear units (ReLUs).\n",
    "\n",
    "    Input:\n",
    "    - x: Inputs, of any shape\n",
    "\n",
    "    Returns a tuple of:\n",
    "    - out: Output, of the same shape as x\n",
    "    - cache: x\n",
    "    \"\"\"\n",
    "    out = x.copy()\n",
    "    ###########################################################################\n",
    "    # TODO: Implement the ReLU forward pass.                                  #\n",
    "    ###########################################################################\n",
    "    out = np.maximum(0,x)\n",
    "    ###########################################################################\n",
    "    #                             END OF YOUR CODE                            #\n",
    "    ###########################################################################\n",
    "    cache = x\n",
    "\n",
    "    return out, cache\n",
    "\n",
    "\n",
    "def relu_backward(dout, cache):\n",
    "    \"\"\"\n",
    "    Computes the backward pass for a layer of rectified linear units (ReLUs).\n",
    "\n",
    "    Input:\n",
    "    - dout: Upstream derivatives, of any shape\n",
    "    - cache: returned by your forward function. Input x, of same shape as dout\n",
    "\n",
    "    Returns:\n",
    "    - dx: Gradient with respect to x\n",
    "    \"\"\"\n",
    "    dx, x = dout.copy(), cache\n",
    "    ###########################################################################\n",
    "    # TODO: Implement the ReLU backward pass.                                 #\n",
    "    ###########################################################################\n",
    "    dx[x <= 0] = 0\n",
    "    ###########################################################################\n",
    "    #                             END OF YOUR CODE                            #\n",
    "    ###########################################################################\n",
    "    return dx\n",
    "\n",
    "\n",
    "def softmax_loss(X, y):\n",
    "    \"\"\"\n",
    "    Computes the loss and gradient for softmax classification.\n",
    "\n",
    "    Inputs:\n",
    "    - X: Input data, of shape (N, C) where x[i, j] is the score for the jth\n",
    "      class for the ith input.\n",
    "    - y: Vector of labels, of shape (N,) where y[i] is the label for X[i] and\n",
    "      0 <= y[i] < C\n",
    "\n",
    "    Returns a tuple of:\n",
    "    - loss: Scalar giving the loss\n",
    "    - dX: Gradient of the loss with respect to x\n",
    "    \"\"\"\n",
    "    loss, dX = None, None\n",
    "\n",
    "    dX = np.exp(X - np.max(X, axis=1, keepdims=True))\n",
    "    dX /= np.sum(dX, axis=1, keepdims=True)\n",
    "    loss = -np.sum(np.log(dX[np.arange(X.shape[0]), y])) / X.shape[0]\n",
    "    dX[np.arange(X.shape[0]), y] -= 1\n",
    "    dX /= X.shape[0]\n",
    "    \n",
    "    return loss, dX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LbFxtS3zK8oz"
   },
   "source": [
    "# 4.2 (b) Two Layer Softmax Classifier\n",
    "\n",
    "In this problem, implement two layer softmax classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "id": "ytvxbx9UpxVL"
   },
   "outputs": [],
   "source": [
    "class SoftmaxClassifier(object):\n",
    "    \"\"\"\n",
    "    A fully-connected neural network with\n",
    "    softmax loss that uses a modular layer design. We assume an input dimension\n",
    "    of D, a hidden dimension of H, and perform classification over C classes.\n",
    "\n",
    "    The architecture should be fc - relu - fc - softmax with one hidden layer\n",
    "\n",
    "    The learnable parameters of the model are stored in the dictionary\n",
    "    self.params that maps parameter names to numpy arrays.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, input_dim=3072, hidden_dim=300, num_classes=10,\n",
    "                 weight_scale=1e-3, reg=0.0):\n",
    "        \"\"\"\n",
    "        Initialize a new network.\n",
    "\n",
    "        Inputs:f\n",
    "        - input_dim: An integer giving the size of the input\n",
    "        - hidden_dim: An integer giving the size of the hidden layer, None\n",
    "          if there's no hidden layer.\n",
    "        - num_classes: An integer giving the number of classes to classify\n",
    "        - weight_scale: Scalar giving the standard deviation for random\n",
    "          initialization of the weights.\n",
    "        \"\"\"\n",
    "        self.params = {}\n",
    "        self.reg = reg\n",
    "        ############################################################################\n",
    "        # TODO: Initialize the weights and biases of the two-layer net. Weights    #\n",
    "        # should be initialized from a Gaussian centered at 0.0 with               #\n",
    "        # standard deviation equal to weight_scale, and biases should be           #\n",
    "        # initialized to zero. All weights and biases should be stored in the      #\n",
    "        # dictionary self.params, with fc weights and biases using the keys        #\n",
    "        # 'W' and 'b', i.e., W1, b1 for the weights and bias in the first linear   #\n",
    "        # layer, W2, b2 for the weights and bias in the second linear layer.       #\n",
    "        ############################################################################\n",
    "        W1 = np.random.normal(0.0, weight_scale, size=(input_dim,hidden_dim))\n",
    "        W2 = np.random.normal(0.0, weight_scale, size=(hidden_dim,num_classes))\n",
    "        b1 = np.zeros(hidden_dim)\n",
    "        b2 = np.zeros(num_classes)\n",
    "        self.params = {\"W1\": W1, \"W2\": W2, \"b1\": b1, \"b2\": b2}\n",
    "\n",
    "\n",
    "\n",
    "        ############################################################################\n",
    "        #                             END OF YOUR CODE                             #\n",
    "        ############################################################################\n",
    "\n",
    "\n",
    "    def forwards_backwards(self, X, y=None):\n",
    "        \"\"\"\n",
    "        Compute loss and gradient for a minibatch of data.\n",
    "\n",
    "        Inputs:\n",
    "        - X: Array of input data of shape (N, Din)\n",
    "        - y: Array of labels, of shape (N,). y[i] gives the label for X[i].\n",
    "\n",
    "        Returns:\n",
    "        If y is None, then run a test-time forward pass of the model and return:\n",
    "        - scores: Array of shape (N, C) giving classification scores, where\n",
    "          scores[i, c] is the classification score for X[i] and class c.\n",
    "\n",
    "        If y is not None, then run a training-time forward and backward pass. And\n",
    "        return a tuple of:\n",
    "        - loss: Scalar value giving the loss\n",
    "        - grads: Dictionary with the same keys as self.params, mapping parameter\n",
    "          names to gradients of the loss with respect to those parameters.\n",
    "        \"\"\"\n",
    "        scores = None\n",
    "        ############################################################################\n",
    "        # TODO: Implement the forward pass for the two-layer net, computing the    #\n",
    "        # class scores for X and storing them in the scores variable.              #\n",
    "        ############################################################################\n",
    "        Z1,cache1 = fc_forward(X,self.params['W1'],self.params['b1'])\n",
    "        A1,cache2 = relu_forward(Z1)\n",
    "        scores,cache3 = fc_forward(A1,self.params['W2'],self.params['b2']) \n",
    "\n",
    "\n",
    "        ############################################################################\n",
    "        #                             END OF YOUR CODE                             #\n",
    "        ############################################################################\n",
    "\n",
    "        # If y is None then we are in test mode so just return scores\n",
    "        if y is None:\n",
    "            return scores\n",
    "\n",
    "        loss, grads = 0, {}\n",
    "        ############################################################################\n",
    "        # TODO: Implement the backward pass for the two-layer net. Store the loss  #\n",
    "        # in the loss variable and gradients in the grads dictionary. Compute data #\n",
    "        # loss using softmax, and make sure that grads[k] holds the gradients for  #\n",
    "        # self.params[k].                                                          # \n",
    "        ############################################################################\n",
    "        loss, grad_L = softmax_loss(scores,y)    \n",
    "        grad_X2,grad_W2,grad_b2 = fc_backward(grad_L, cache3)\n",
    "        grad_Z1 = relu_backward(grad_X2,cache2)\n",
    "        grad_X1,grad_W1,grad_b1 = fc_backward(grad_Z1,cache1)\n",
    "        grads = {\"W1\": grad_W1, \"W2\": grad_W2, \"b1\": grad_b1, \"b2\": grad_b2}\n",
    "        \n",
    "\n",
    "        ############################################################################\n",
    "        #                             END OF YOUR CODE                             #\n",
    "        ############################################################################\n",
    "        ############################################################################\n",
    "        # TODO: 4.2(g)(EECS 504 only) Add L2 regularization                        # \n",
    "        ############################################################################\n",
    "        grads['W1'] = grads['W1'] + 2*self.reg*grads['W1']\n",
    "        grads['W2'] = grads['W2'] + 2*self.reg*grads['W2']\n",
    "\n",
    "        ############################################################################\n",
    "        #                             END OF YOUR CODE                             #\n",
    "        ############################################################################\n",
    "        return loss, grads\n",
    "\n",
    "  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lwp0waIL1h_e"
   },
   "source": [
    "# 4.2(c) Training\n",
    "\n",
    "In this problem, you need to preprocess the images and set up model hyperparameters. Notice that adjust the training and val split is optional."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "id": "kZPtQzXGMoCg"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Iteration 1 / 25000) loss: 2.322218\n",
      "(Epoch 0 / 10) train acc: 0.124000; val_acc: 0.113400\n",
      "(Iteration 1001 / 25000) loss: 2.131884\n",
      "(Iteration 2001 / 25000) loss: 1.860382\n",
      "(Epoch 1 / 10) train acc: 0.372000; val_acc: 0.336100\n",
      "(Iteration 3001 / 25000) loss: 1.790017\n",
      "(Iteration 4001 / 25000) loss: 1.775864\n",
      "(Epoch 2 / 10) train acc: 0.391000; val_acc: 0.371800\n",
      "(Iteration 5001 / 25000) loss: 1.801321\n",
      "(Iteration 6001 / 25000) loss: 1.675315\n",
      "(Iteration 7001 / 25000) loss: 1.636754\n",
      "(Epoch 3 / 10) train acc: 0.419000; val_acc: 0.398000\n",
      "(Iteration 8001 / 25000) loss: 1.437445\n",
      "(Iteration 9001 / 25000) loss: 1.645791\n",
      "(Epoch 4 / 10) train acc: 0.404000; val_acc: 0.416600\n",
      "(Iteration 10001 / 25000) loss: 1.690557\n",
      "(Iteration 11001 / 25000) loss: 1.100124\n",
      "(Iteration 12001 / 25000) loss: 1.397812\n",
      "(Epoch 5 / 10) train acc: 0.452000; val_acc: 0.429500\n",
      "(Iteration 13001 / 25000) loss: 1.500188\n",
      "(Iteration 14001 / 25000) loss: 1.475837\n",
      "(Epoch 6 / 10) train acc: 0.445000; val_acc: 0.431800\n",
      "(Iteration 15001 / 25000) loss: 1.881941\n",
      "(Iteration 16001 / 25000) loss: 1.298211\n",
      "(Iteration 17001 / 25000) loss: 1.642308\n",
      "(Epoch 7 / 10) train acc: 0.489000; val_acc: 0.435400\n",
      "(Iteration 18001 / 25000) loss: 1.270702\n",
      "(Iteration 19001 / 25000) loss: 1.777610\n",
      "(Epoch 8 / 10) train acc: 0.483000; val_acc: 0.443700\n",
      "(Iteration 20001 / 25000) loss: 1.499686\n",
      "(Iteration 21001 / 25000) loss: 1.498076\n",
      "(Iteration 22001 / 25000) loss: 1.181388\n",
      "(Epoch 9 / 10) train acc: 0.485000; val_acc: 0.451900\n",
      "(Iteration 23001 / 25000) loss: 1.467594\n",
      "(Iteration 24001 / 25000) loss: 1.185922\n",
      "(Epoch 10 / 10) train acc: 0.472000; val_acc: 0.450500\n"
     ]
    }
   ],
   "source": [
    "def unpickle(file):\n",
    "    with open(file, 'rb') as fo:\n",
    "        dict = pickle.load(fo, encoding=\"latin1\")\n",
    "    return dict\n",
    "\n",
    "def load_cifar10():\n",
    "    data = {}\n",
    "    meta = unpickle(\"cifar-10-batches-py/batches.meta\")\n",
    "    batch1 = unpickle(\"cifar-10-batches-py/data_batch_1\")\n",
    "    batch2 = unpickle(\"cifar-10-batches-py/data_batch_2\")\n",
    "    batch3 = unpickle(\"cifar-10-batches-py/data_batch_3\")\n",
    "    batch4 = unpickle(\"cifar-10-batches-py/data_batch_4\")\n",
    "    batch5 = unpickle(\"cifar-10-batches-py/data_batch_5\")\n",
    "    test_batch = unpickle(\"cifar-10-batches-py/test_batch\")\n",
    "    X_train = np.vstack((batch1['data'], batch2['data'], batch3['data'],\\\n",
    "                         batch4['data'], batch5['data']))\n",
    "    Y_train = np.array(batch1['labels'] + batch2['labels'] + batch3['labels'] + \n",
    "                       batch4['labels'] + batch5['labels'])\n",
    "    X_test = test_batch['data']\n",
    "    Y_test = test_batch['labels']\n",
    "    \n",
    "    #Preprocess images here                                     \n",
    "    X_train = (X_train-np.mean(X_train,axis=1,keepdims=True))/np.std(X_train,axis=1,keepdims=True)\n",
    "    X_test = (X_test-np.mean(X_test,axis=1,keepdims=True))/np.std(X_test,axis=1,keepdims=True)\n",
    "\n",
    "    data['X_train'] = X_train[:40000]\n",
    "    data['y_train'] = Y_train[:40000]\n",
    "    data['X_val'] = X_train[40000:]\n",
    "    data['y_val'] = Y_train[40000:]\n",
    "    data['X_test'] = X_test\n",
    "    data['y_test'] = Y_test\n",
    "    return data\n",
    "\n",
    "def testNetwork(model, X, y, num_samples=None, batch_size=100):\n",
    "    \"\"\"\n",
    "    Check accuracy of the model on the provided data.\n",
    "\n",
    "    Inputs:\n",
    "    - model: Image classifier\n",
    "    - X: Array of data, of shape (N, d_1, ..., d_k)\n",
    "    - y: Array of labels, of shape (N,)\n",
    "    - num_samples: If not None, subsample the data and only test the model\n",
    "      on num_samples datapoints.\n",
    "    - batch_size: Split X and y into batches of this size to avoid using\n",
    "      too much memory.\n",
    "\n",
    "    Returns:\n",
    "    - acc: Scalar giving the fraction of instances that were correctly\n",
    "      classified by the model.\n",
    "    \"\"\"\n",
    "\n",
    "    # Subsample the data\n",
    "    N = X.shape[0]\n",
    "    if num_samples is not None and N > num_samples:\n",
    "        mask = np.random.choice(N, num_samples)\n",
    "        N = num_samples\n",
    "        X = X[mask]\n",
    "        y = y[mask]\n",
    "\n",
    "    # Compute predictions in batches\n",
    "    num_batches = N // batch_size\n",
    "    if N % batch_size != 0:\n",
    "        num_batches += 1\n",
    "    y_pred = []\n",
    "    for i in range(num_batches):\n",
    "        start = i * batch_size\n",
    "        end = (i + 1) * batch_size\n",
    "        scores = model.forwards_backwards(X[start:end])\n",
    "        y_pred.append(np.argmax(scores, axis=1))\n",
    "    y_pred = np.hstack(y_pred)\n",
    "    acc = np.mean(y_pred == y)\n",
    "\n",
    "    return acc\n",
    "\n",
    "def SGD(W,dW, learning_rate=1e-3):\n",
    "    \"\"\" Apply a gradient descent step on weight W \n",
    "    Inputs:\n",
    "        W : Weight matrix\n",
    "        dW : gradient of weight, same shape as W\n",
    "        learning_rate : Learning rate. Defaults to 1e-3.\n",
    "    Returns:\n",
    "        new_W: Updated weight matrix\n",
    "    \"\"\"\n",
    "\n",
    "    # Apply a gradient descent step on weight W using the gradient dW and the specified learning rate.\n",
    "    new_W = W - learning_rate * dW\n",
    "\n",
    "    return new_W\n",
    "\n",
    "def trainNetwork(model, data, **kwargs):\n",
    "    \"\"\"\n",
    "     Required arguments:\n",
    "    - model: Image classifier\n",
    "    - data: A dictionary of training and validation data containing:\n",
    "      'X_train': Array, shape (N_train, d_1, ..., d_k) of training images\n",
    "      'X_val': Array, shape (N_val, d_1, ..., d_k) of validation images\n",
    "      'y_train': Array, shape (N_train,) of labels for training images\n",
    "      'y_val': Array, shape (N_val,) of labels for validation images\n",
    "\n",
    "    Optional arguments:\n",
    "    - learning_rate: A scalar for initial learning rate.\n",
    "    - lr_decay: A scalar for learning rate decay; after each epoch the\n",
    "      learning rate is multiplied by this value.\n",
    "    - batch_size: Size of minibatches used to compute loss and gradient\n",
    "      during training.\n",
    "    - num_epochs: The number of epochs to run for during training.\n",
    "    - print_every: Integer; training losses will be printed every\n",
    "      print_every iterations.\n",
    "    - verbose: Boolean; if set to false then no output will be printed\n",
    "      during training.\n",
    "    - num_train_samples: Number of training samples used to check training\n",
    "      accuracy; default is 1000; set to None to use entire training set.\n",
    "    - num_val_samples: Number of validation samples to use to check val\n",
    "      accuracy; default is None, which uses the entire validation set.\n",
    "    - optimizer: Choice of using either 'SGD' or 'SGD_Momentum' for updating weights; default is SGD.\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    learning_rate =  kwargs.pop('learning_rate', 1e-3)\n",
    "    lr_decay = kwargs.pop('lr_decay', 1.0)\n",
    "    batch_size = kwargs.pop('batch_size', 100)\n",
    "    num_epochs = kwargs.pop('num_epochs', 10)\n",
    "    num_train_samples = kwargs.pop('num_train_samples', 1000)\n",
    "    num_val_samples = kwargs.pop('num_val_samples', None)\n",
    "    print_every = kwargs.pop('print_every', 10)   \n",
    "    verbose = kwargs.pop('verbose', True)\n",
    "    optimizer = kwargs.pop('optimizer', 'SGD')\n",
    "    \n",
    "    epoch = 0\n",
    "    best_val_acc = 0\n",
    "    best_params = {}\n",
    "    loss_history = []\n",
    "    train_acc_history = []\n",
    "    val_acc_history = []\n",
    "    \n",
    "    \n",
    "    num_train = data['X_train'].shape[0]\n",
    "    iterations_per_epoch = max(num_train // batch_size, 1)\n",
    "    num_iterations = num_epochs * iterations_per_epoch\n",
    "    \n",
    "    #Initialize velocity dictionary if optimizer is SGD_Momentum\n",
    "    if optimizer == 'SGD_Momentum':\n",
    "        velocity_dict = {p:np.zeros(w.shape) for p,w in model.params.items()}\n",
    "      \n",
    "    for t in range(num_iterations): \n",
    "        # Make a minibatch of training data\n",
    "        batch_mask = np.random.choice(num_train, batch_size)\n",
    "        X_batch = data['X_train'][batch_mask]\n",
    "        y_batch = data['y_train'][batch_mask]\n",
    "        \n",
    "        # Compute loss and gradient\n",
    "        loss, grads = model.forwards_backwards(X_batch, y_batch)\n",
    "        loss_history.append(loss)\n",
    "\n",
    "        # Perform a parameter update\n",
    "        if optimizer == 'SGD':\n",
    "            for p, w in model.params.items():\n",
    "                model.params[p] = SGD(w,grads[p], learning_rate=learning_rate)\n",
    "\n",
    "        elif optimizer == 'SGD_Momentum':\n",
    "            for p, w in model.params.items():\n",
    "                model.params[p], velocity_dict[p] = SGD_Momentum(w, grads[p], velocity_dict[p], beta=0.5, learning_rate=learning_rate)\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "        # Print training loss\n",
    "        if verbose and t % print_every == 0:\n",
    "            print('(Iteration %d / %d) loss: %f' % (\n",
    "                   t + 1, num_iterations, loss_history[-1]))\n",
    "         \n",
    "        # At the end of every epoch, increment the epoch counter and decay\n",
    "        # the learning rate.\n",
    "        epoch_end = (t + 1) % iterations_per_epoch == 0\n",
    "        if epoch_end:\n",
    "            epoch += 1\n",
    "            learning_rate *= lr_decay\n",
    "        \n",
    "        # Check train and val accuracy on the first iteration, the last\n",
    "        # iteration, and at the end of each epoch.\n",
    "        first_it = (t == 0)\n",
    "        last_it = (t == num_iterations - 1)\n",
    "        if first_it or last_it or epoch_end:\n",
    "            train_acc = testNetwork(model, data['X_train'], data['y_train'],\n",
    "                num_samples= num_train_samples)\n",
    "            val_acc = testNetwork(model, data['X_val'], data['y_val'],\n",
    "                num_samples=num_val_samples)\n",
    "            train_acc_history.append(train_acc)\n",
    "            val_acc_history.append(val_acc)\n",
    "\n",
    "            if verbose:\n",
    "                print('(Epoch %d / %d) train acc: %f; val_acc: %f' % (\n",
    "                       epoch, num_epochs, train_acc, val_acc))\n",
    "\n",
    "            # Keep track of the best model\n",
    "            if val_acc > best_val_acc:\n",
    "                best_val_acc = val_acc\n",
    "                best_params = {}\n",
    "                for k, v in model.params.items():\n",
    "                    best_params[k] = v.copy()\n",
    "        \n",
    "    model.params = best_params\n",
    "        \n",
    "    return model, train_acc_history, val_acc_history\n",
    "        \n",
    "\n",
    "# load data\n",
    "data = load_cifar10() \n",
    "train_data = { k: data[k] for k in ['X_train', 'y_train', \n",
    "                                    'X_val', 'y_val']}\n",
    "\n",
    "# initialize model\n",
    "model_SGD = SoftmaxClassifier(hidden_dim = 300, weight_scale=1e-2)\n",
    "\n",
    "#######################################################################\n",
    "# TODO: Set up model hyperparameters for SGD                          #\n",
    "#######################################################################\n",
    "\n",
    "# set the hyperparameter\n",
    "learning_rate_SGD = 1e-3\n",
    "lr_decay_SGD = 0.9\n",
    "batch_size_SGD = 16\n",
    "\n",
    "# start training using SGD\n",
    "model_SGD, train_acc_history_SGD, val_acc_history_SGD = trainNetwork(\n",
    "    model_SGD, train_data, \n",
    "    learning_rate = learning_rate_SGD,\n",
    "    lr_decay=lr_decay_SGD, \n",
    "    batch_size=batch_size_SGD,\n",
    "    num_epochs=10, \n",
    "    print_every=1000, optimizer = 'SGD')\n",
    "#######################################################################\n",
    "#                         END OF YOUR CODE                            #\n",
    "#######################################################################\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e2ilTVXIw_7q"
   },
   "source": [
    "# 4.2(d) Training with SGD_Momentum\n",
    "\n",
    "The model above was trained using SGD. Now implement the SGD with momentum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "id": "54jGVPZOXtV6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Iteration 1 / 25000) loss: 2.292618\n",
      "(Epoch 0 / 10) train acc: 0.081000; val_acc: 0.093300\n",
      "(Iteration 1001 / 25000) loss: 1.900433\n",
      "(Iteration 2001 / 25000) loss: 1.691958\n",
      "(Epoch 1 / 10) train acc: 0.389000; val_acc: 0.379900\n",
      "(Iteration 3001 / 25000) loss: 2.063060\n",
      "(Iteration 4001 / 25000) loss: 1.609582\n",
      "(Epoch 2 / 10) train acc: 0.448000; val_acc: 0.416900\n",
      "(Iteration 5001 / 25000) loss: 1.441299\n",
      "(Iteration 6001 / 25000) loss: 2.458209\n",
      "(Iteration 7001 / 25000) loss: 1.827469\n",
      "(Epoch 3 / 10) train acc: 0.475000; val_acc: 0.436100\n",
      "(Iteration 8001 / 25000) loss: 1.967341\n",
      "(Iteration 9001 / 25000) loss: 1.189027\n",
      "(Epoch 4 / 10) train acc: 0.496000; val_acc: 0.454100\n",
      "(Iteration 10001 / 25000) loss: 1.191937\n",
      "(Iteration 11001 / 25000) loss: 1.776392\n",
      "(Iteration 12001 / 25000) loss: 1.480691\n",
      "(Epoch 5 / 10) train acc: 0.484000; val_acc: 0.464600\n",
      "(Iteration 13001 / 25000) loss: 1.609945\n",
      "(Iteration 14001 / 25000) loss: 1.138711\n",
      "(Epoch 6 / 10) train acc: 0.502000; val_acc: 0.470300\n",
      "(Iteration 15001 / 25000) loss: 1.435983\n",
      "(Iteration 16001 / 25000) loss: 1.371153\n",
      "(Iteration 17001 / 25000) loss: 1.186552\n",
      "(Epoch 7 / 10) train acc: 0.542000; val_acc: 0.477600\n",
      "(Iteration 18001 / 25000) loss: 1.290375\n",
      "(Iteration 19001 / 25000) loss: 1.215643\n",
      "(Epoch 8 / 10) train acc: 0.517000; val_acc: 0.483400\n",
      "(Iteration 20001 / 25000) loss: 1.353611\n",
      "(Iteration 21001 / 25000) loss: 1.073605\n",
      "(Iteration 22001 / 25000) loss: 1.457658\n",
      "(Epoch 9 / 10) train acc: 0.534000; val_acc: 0.488300\n",
      "(Iteration 23001 / 25000) loss: 1.391999\n",
      "(Iteration 24001 / 25000) loss: 1.825682\n",
      "(Epoch 10 / 10) train acc: 0.532000; val_acc: 0.491200\n"
     ]
    }
   ],
   "source": [
    "def SGD_Momentum(W, dW, velocity, beta=0.5, learning_rate=1e-3):\n",
    "    \"\"\" Apply a gradient descent with momentum update on weight W\n",
    "    Inputs:\n",
    "        W : Weight matrix\n",
    "        dW : gradient of weight, same shape as W\n",
    "        velocity : velocity matrix, same shape as W\n",
    "        beta : scalar value in range [0,1] weighting the velocity matrix. Setting it to 0 should make SGD_Momentum same as SGD. \n",
    "               Defaults to 0.5.\n",
    "        learning_rate : Learning rate. Defaults to 1e-3.\n",
    "    Returns:\n",
    "        new_W: Updated weight matrix\n",
    "        new_velocity: Updated velocity matrix\n",
    "    \"\"\"\n",
    "    #######################################################################\n",
    "    # TODO: Apply a gradient descent step on weight W using the gradient dW and the specified learning rate.\n",
    "    # 1. Calculate the new velocity by using the velocity of last iteration (input velocity) and gradient\n",
    "    # 2. Update the weights using the new_velocity\n",
    "    #######################################################################\n",
    "    new_velocity = beta*velocity + learning_rate*dW\n",
    "    new_W = W - new_velocity\n",
    "    \n",
    "\n",
    "\n",
    "    #######################################################################\n",
    "    #                         END OF YOUR CODE                            #\n",
    "    #######################################################################\n",
    "    return new_W, new_velocity\n",
    "\n",
    "# initialize model\n",
    "model_SGD_Momentum = SoftmaxClassifier(hidden_dim = 300, weight_scale=1e-2)\n",
    "\n",
    "# start training \n",
    "#Using SGD_Momentum as optimizer for trainning for training\n",
    "model_SGD_Momentum, train_acc_history_SGD_Momentum, val_acc_history_SGD_Momentum = trainNetwork(\n",
    "    model_SGD_Momentum, train_data, \n",
    "    learning_rate = learning_rate_SGD,\n",
    "    lr_decay=lr_decay_SGD, \n",
    "    batch_size=batch_size_SGD,\n",
    "    num_epochs=10, \n",
    "    print_every=1000, optimizer = 'SGD_Momentum')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fcovGmpXvXXa"
   },
   "source": [
    "# 4.2(e) Report Accuracy\n",
    "\n",
    "Run the given code and report the accuracy of model_SGD and model_SGD_Momentum on test set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "FwCq8pBhu6dz"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy of model_SGD: 0.4585\n",
      "Test accuracy of model_SGD_Momentum: 0.4973\n"
     ]
    }
   ],
   "source": [
    "# report test accuracy\n",
    "acc = testNetwork(model_SGD, data['X_test'], data['y_test'])\n",
    "print(\"Test accuracy of model_SGD: {}\".format(acc))\n",
    "# report test accuracy\n",
    "acc = testNetwork(model_SGD_Momentum, data['X_test'], data['y_test'])\n",
    "print(\"Test accuracy of model_SGD_Momentum: {}\".format(acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oTrmbULS7i2N"
   },
   "source": [
    "# 4.2(f) Plot\n",
    "\n",
    "Using the train_acc_history and val_acc_history, plot the train & val accuracy versus epochs on one plot, using SGD and SGD_Momentum as optimizer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "id": "SPjtnbya9S7g"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAAAsTAAALEwEAmpwYAAA3oUlEQVR4nO3deXxU5b348c83+w5ZWBICJKxhMWxhURQRtQU3WqWtW63eq1Rb6/Jrb7XtvbXe7q211rbWqrW21luLu7VuFUFAAVmM7AiEQEIgCdkI2ZP5/v44JzCEBAbMMJnM9/16zWvmPOfMme9keb7nPM9zniOqijHGmNAVFugAjDHGBJYlAmOMCXGWCIwxJsRZIjDGmBBnicAYY0KcJQJjjAlxlgiMMSbEWSIwnRKRc0XkAxGpEZFKEXlfRKZ6rU8XkcdFpEREDotIgYg8JSI57vosEVF33WERKRWR10Tk4pN8rrrbRniVRYhImYj0uIteRGSpiNwcgM99SkRaRSTjTH+26X0sEZjjiEgS8BrwWyAFGATcDzS561OBD4A44DwgEZgMvAd0rOj7qmoCMAH4N/CSiNx4khCqgXley5cAVaf9hXoZEYkHrgJqgOvO8GdHnHwrE3RU1R72OOYB5AHVJ1j/I+BjIOwE22QBCkR0KP8WUNrVe933/DfwnFfZ88D3nD/XI2UZwKtAJbATuMVr3Q+A54C/AbXARmAU8B2gDCgCPuO1fR/gT8B+YJ/7/cLddTcCK4AHcJLRbmCeu+7HQBvQCBwGftfZ9waWAjd77e994Nc4Ca8AOMctL3Lj+8pJfj83uNveCWzqsC4F+DNQ4sb7ste6+UA+cAjYBcx1ywuBizr8/P7W4ff4n8BeYJlb/hxwACcZLQPGeb0/FvgVsMddv8It+xfwjQ7xbgA+F+i/+VB/2BmB6cwnQJuI/EVE5olIcof1FwEvqarnNPb9ItAfGH2CbV4GZolIXxHpi3PW8UqHbf4OFOMkhAXAT0TkQq/1lwNPA8nAR8BbOGfAg4D/Bf7ote1fgFZgBDAJ+Azg3dwzHdgOpAG/AP4kIqKq3wOWA7eraoKq3u7D92/f3wYgFfg/4Flgqvv51wO/E5GEE7z/K+73fxbIEZHJXuuexjlTG4fzc/41gIhMA/4K/BfQF5iFkwB8dT4wBvisu/wGMNL9jPXAM17bPgBMwUlwKcC3AQ/Oz/n69o1EZALO7+P1U4jD+EOgM5E9euYD55/+KZzKthXn6HuAu24ncKvXtlfgHN3WAm+7ZVl0fkYQ45bP7OJzFadCfAL4KnAr8Lhbpu42g3GOxBO93vdT4Cn39Q+Af3utuxzniL39KD/R/Zy+wACcJq9Yr+2vAZa4r28Ednqti3PfO9BdXop7tN/V9+b4M4IdXuvOcrcf4FVWAUzs4uczBKdSneguvwX8xn2d7q5L7uR9fwR+3cU+Czn5GcGwE/yt9HW36YOTbBuACZ1sF41zBjfSXX4AeCTQf+v2sDMC0wVV3aqqN6pqJjAe58j7IXd1BU6l077tq6raF7gbiDrJrge5z5Un2e6vOE0gN7ivvWUAlapa61W2x2vf4DQ/tWsADqpqm9cyQAIwFIgE9otItYhU41Sa/b3ef6D9harWe733dHWMDVXtWNbV/r8MbFXVfHf5GeBaEYnESZCVqtpZf8pgnOag01XU/kJEwkXkZyKyS0QOcfTMIs19xHT2WaraBCwCrheRMJyE+/SniMl0E0sE5qRUdRvO2cF4t2gx8Dn3n/lUfR6nHXz7SbZbjpNsBuC0MXsrAVJEJNGrbAhO+/6pKsI5I0hT1b7uI0lVx/n4/o4jmerc5zivsoGnEVdXbgCGicgBETkAPIhT+c7D+S4pbnNaR0XA8C72WcfJ4/X+ntfi9DdchHMWkOWWC3AQp8+kq8/6C04H94VAvaqu7GI7cwZZIjDHEZEcEfmmiGS6y4Nxjt5WuZs8iNP2/rSIDBdHIjDxBPscICK3A/cB39GT9C+o03ZwOXCF+9p7XRHOqKWfikiMiOTidGY+c/yeTkxV9wNvA78SkSQRCXO/0/k+7qIUGOa1v3KchHS9e+T8H3RdKZ4SETnb3dc0nJ/1RJzk/H84Hcz7cdruHxGRZBGJFJFZ7tv/BNwkIhe633FQ+1BfnA7kq93t83D6XE4kESd5VuAkkJ+0r3B/r08CD4pIhvszOFtEot31K3Gar36FnQ30GJYITGdqcTo0V4tIHU4C2AR8E0BVDwIzcI78Vrjb5+NUELd12Fe1u4+NOMNAv6CqT/oShKpuVtXNXay+BudItAR4CbhPVf/t4/fr6AacJq0tOCNtnser6eskfgMsEJEqEXnYLbsFp1O2AqfT9oPTjKujrwCvqOpGVT3Q/nBjuExEUnCajlqAbThnXncBqOqHwE04ncc1OEN9h7r7/R+cBFOFM0z4/04Sx19xmuL24fzMVnVY/y2c3/canCbAn3NsXfNXnL6Rv53Cdzd+JB0Otowxxq9E5AZgoaqeG+hYjMPOCIwxZ4yIxAFfAx4LdCzmKEsExpgzQkQ+C5Tj9KucrPnJnEHWNGSMMSHOzgiMMSbEBd0EUmlpaZqVlRXoMIwxJqisW7fuoKr262xd0CWCrKws1q5dG+gwjDEmqIjInq7WWdOQMcaEOEsExhgT4iwRGGNMiAu6PoLOtLS0UFxcTGNjY6BD6TViYmLIzMwkMjIy0KEYY/ysVySC4uJiEhMTycrKQkQCHU7QU1UqKiooLi4mOzs70OEYY/ysVzQNNTY2kpqaakmgm4gIqampdoZlTIjoFYkAsCTQzeznaUzo6DWJwBhzZpVUN/DU+7vZtK8Gm6omuFki6AbV1dU88sgjp/y+Sy65hOrq6hNu8/3vf5933nnnNCMzpvvVNbXy4NvbmfOrpfzgn1u47LcruOjB93h48Q4KD9adfAemxwm6Sefy8vK045XFW7duZcyYMQGKCAoLC7nsssvYtGnTMeVtbW2Eh4cHKKpPL9A/V9OztHmUF9YV88u3t1Ne28QVEzK49fzh5BdV80r+Plbvdm5DPWFwXz43MYNLc9PpnxgT4KhNOxFZp6p5na3rFaOGAu3ee+9l165dTJw4kcjISBISEkhPTyc/P58tW7bwuc99jqKiIhobG7nzzjtZuHAhcHS6jMOHDzNv3jzOPfdcPvjgAwYNGsQrr7xCbGwsN954I5dddhkLFiwgKyuLr3zlK/zzn/+kpaWF5557jpycHMrLy7n22mupqKhg6tSpvPnmm6xbt460tLQA/2RMb/HBzoP88F9b2br/EJOH9OWPX57C5CHJAIzNSOLa6UMoqW7gtQ0lvPxRCff/cws/fG0LM0ekccWEDD47fiBJMcE/FFlVOdTYSkSYEB0RRkR472hU6XWJ4P5/bmZLyaFu3efYjCTuu7zre5n/7Gc/Y9OmTeTn57N06VIuvfRSNm3adGTo5ZNPPklKSgoNDQ1MnTqVq666itTU1GP2sWPHDv7+97/z+OOP88UvfpEXXniB66+//rjPSktLY/369TzyyCM88MADPPHEE9x///3MmTOH73znO7z55ps89pjd88N0j4Lyw/zk9W28s7WUQX1j+e01k7gsN73TwQQZfWNZOGs4C2cNZ0dpLa9+XMIr+SX81/Mb+N7Lm7hoTH+umDCI2aP7ERMZHGfKHo+yvbSWNYWVfLjbeZTVNh1ZHyYQFRFGVHgYURHhREeEER0R5pS55dGR7euPbnNknfvauywqIvzYsogwot39pPeJJaNvbLd/z16XCHqCadOmHTP+/uGHH+all14CoKioiB07dhyXCLKzs5k4cSIAU6ZMobCwsNN9X3nllUe2efHFFwFYsWLFkf3PnTuX5OTk7vw6JgRV1TXzm8U7+NuqPcREhnPP3BxumpnlcwU+ckAi3/zMaP7fxaP4qKiaV/NLeG1DCa9vPEBiTATzxg9k/sRBzBiWSnhYzxmh1tzqYeO+GtYUVrJmdyVrCis51NgKQHqfGM4ensq4jCRUnW2b2zw0t3poch9Hy9qOLDe1eKhtbD2y3dHnNprbnNe+ttDfev5w7p2X0+3fu9clghMduZ8p8fHxR14vXbqUd955h5UrVxIXF8fs2bM7HZ8fHR195HV4eDgNDQ2d7rt9u/DwcFpbnT/QYOvnMT1Xc6uHp1ft4eHFO6htbOHqaUO4+6JR9EuMPvmbOyEiTB6SzOQhyfz3pWP4YFcFr+Q7CWHR2mL6J0Zz+YQM5k/M4KxBfc74sOX65lY+2lvN6t1Oxf9RURWNLR4AhvWL55Kz0pmWncLUrBQyk2P9Ep+q0upRJ4m4iaSpxUNz29Fk0p48BiV3/9kA9MJEEAiJiYnU1tZ2uq6mpobk5GTi4uLYtm0bq1at6vbPP/fcc1m0aBH33HMPb7/9NlVVVd3+GaZ3U1Xe3lLKT1/fSmFFPeeNTOO/Lx3L6IGJ3fYZEeFhzBrVj1mj+vHjlvEs3lrGK/n7eHrlHv60YjfZafFc4SaFYf0Suu1zvVXXN7OmsIoPd1fwYWEVm/fV0OpRwsRpAr5m2hCmZ6eQl5VCWsLpJb9TJSJEhguR4WHEn5mPPI4lgm6QmprKzJkzGT9+PLGxsQwYMODIurlz5/Loo4+Sm5vL6NGjmTFjRrd//n333cc111zDP/7xD84//3zS09NJTOy+f2DTu23aV8OP/rWFVQWVjOyfwFM3TWX26P5+/cyYyHAuzU3n0tx0aupbeHPzfl7JL+Hhd3fwm8U7yM3swxUTMrh8QgYDkk5/5NH+mgY+dJt4PtxdySelhwGICg9j4uC+fPX8YUzNSmHK0GQSe0Fn9umy4aO9QFNTE+Hh4URERLBy5Upuu+028vPzP/V+Q/3n2tuVHmrkl29t54X1xSTHRXH3xaO4ZurggI6EOVDTyGsbnE7mjftqEIGzh6Uyf2IGc8en0ye268paVdl9sM7p1C10Kv+iSqeJNSE6gslDk5nuNvPkZvYJmg7r7mLDR3u5vXv38sUvfhGPx0NUVBSPP/54oEMyPVh9cyuPL9vNo+/tos2jLDxvGF+fM6JHDO8c2CeGm88bxs3nDWNX+WFezS/hlfx93PPCRv7n5c1ckNOP+RMHMSenP5HhYWzdf+jI0f6awioOHnZG9KTGRzE1K4WbzslmWnYKOQMTe81QT3+wRNALjBw5ko8++ijQYZgezuNRXvpoH798azsHDjVy6Vnp3DM3hyGpcYEOrVPD+yVw98WjuOuikWworuGV/BL+uaGEtzaXkhAdgQC1Tc6AiczkWGaNTGNqdgrTslMYlhZv82WdAksExoSA1QUV/PBfW9i07xATMvvwu2snkZeVEuiwfCIiTBjclwmD+/K9S8ewqqCC1zbsJ0w4MqLHH2PrQ4klAmN6scKDdfzsjW28ufkA6X1ieOhLE7liQgZhPWjs/qkIDxNmjkhj5gi7ar47WSIwpheqqW/ht+/u4C8rC4kMD+ObF4/i5vOGERsVWh2kxjeWCIzpRVraPPzf6r089M4nVDe08MUpg/nmZ0bR/1MMwTS9n1+70UVkrohsF5GdInJvJ+tni0iNiOS7j+/7M56eIiHBuVimpKSEBQsWdLrN7Nmz6ThMtqOHHnqI+vr6I8u+TGtteidVZfHWUj770DLue3UzY9KTeO0b5/LzBbmWBMxJ+e2MQETCgd8DFwPFwBoReVVVt3TYdLmqXuavOHqyjIwMnn/++dN+/0MPPcT1119PXJwz6uP111/vrtBMkGhsaWP9nioeWbqLFTsPMiwtniduyOPCMf1t1IzxmT+bhqYBO1W1AEBEngXmAx0TQdC75557GDp0KF/72tcA+MEPfoCIsGzZMqqqqmhpaeFHP/oR8+fPP+Z93vcxaGho4KabbmLLli2MGTPmmLmGbrvtNtasWUNDQwMLFizg/vvv5+GHH6akpIQLLriAtLQ0lixZcmRa67S0NB588EGefPJJAG6++WbuuusuCgsLu5zu2gSH5lYPHxdXs3JXBSt3VbB+bxVNrR76xEZy3+VjuX7GUCJtvLw5Rf5MBIOAIq/lYmB6J9udLSIfAyXAt1R1c8cNRGQhsBBgyJAhJ/7UN+6FAxtPM+QuDDwL5v2sy9VXX301d91115FEsGjRIt58803uvvtukpKSOHjwIDNmzOCKK67o8ijtD3/4A3FxcWzYsIENGzYwefLkI+t+/OMfk5KSQltbGxdeeCEbNmzgjjvu4MEHH2TJkiXH3Xdg3bp1/PnPf2b16tWoKtOnT+f8888nOTnZ5+muTc/Q2uZhw74aVu6qYFVBBWsLq2hoaQNgTHoS100fytnDUzl7eCoJ0dblZ06PP/9yOqvxOs5nsR4YqqqHReQS4GVg5HFvUn0MeAycKSa6Oc5PbdKkSZSVlVFSUkJ5eTnJycmkp6dz9913s2zZMsLCwti3bx+lpaUMHDiw030sW7aMO+64A4Dc3Fxyc3OPrFu0aBGPPfYYra2t7N+/ny1bthyzvqMVK1bw+c9//sgsqFdeeSXLly/niiuu8Hm662BT29jCih0HWbytjNJDjQzvl8CoAYmMGpDAyAGJJ5yaoCdp8yibS5yKf2VBBWt2V1LX7FT8owck8qWpg5kxLJXp2Skkx0cFOFrTW/gzERQDg72WM3GO+o9Q1UNer18XkUdEJE1VD572p57gyN2fFixYwPPPP8+BAwe4+uqreeaZZygvL2fdunVERkaSlZXV6fTT3jo7W9i9ezcPPPAAa9asITk5mRtvvPGk+znR/FG+TncdDAoP1rF4WxlLtpWxencFLW1KUkwEQ1PjWbS2iHq3AgUYmBTDyAFHk8OoAYmMHJAY8KNoj0fZsv8Qqwqcpp4Pd1ceuVp2eL94Pj95EGcPS2P6sDM3G6YJPf78L1gDjBSRbGAfcDVwrfcGIjIQKFVVFZFpOKOYKvwYk99cffXV3HLLLRw8eJD33nuPRYsW0b9/fyIjI1myZAl79uw54ftnzZrFM888wwUXXMCmTZvYsGEDAIcOHSI+Pp4+ffpQWlrKG2+8wezZs4Gj0193bBqaNWsWN954I/feey+qyksvvcTTTz/tl+99JrW0eVhTWMm7W8t4d3sZBeXOjdJH9E/gP2ZmMyenP1OGJhMRHobHo+yrbmBHWS2flB7mkwO1fFJWyzOr9xyZbx5gUN9YRg5IYLSbGEYNSGBE/wTiovzzr+HxKJ+U1R5p41+9u5KahhYAslLjuGxCOjOGpXL2sFQb7dObtDZDS737aHCem+uPLWuuc9e1P3dSNnY+TL6h28PzWyJQ1VYRuR14CwgHnlTVzSJyq7v+UWABcJuItAINwNUabNOhusaNG0dtbS2DBg0iPT2d6667jssvv5y8vDwmTpxITs6J7yp02223cdNNN5Gbm8vEiROZNm0aABMmTGDSpEmMGzeOYcOGMXPmzCPvWbhwIfPmzSM9PZ0lS5YcKZ88eTI33njjkX3cfPPNTJo0KSibgSoON7F0eznvbi9j2fZyaptaiQoPY/qwFG6YMZQ5OQM6nSsnLEwYnBLH4JQ45uQcnRa8zaMUVdbzSWktO8oO80mpkyg+2FlBc5uTIERgcHLckWYlJ0kkMLxfwinPWKmq7Co/fKSpZ1VBJZV1zQAMTonls+MGcPbwVGYMSyW9j3Xa9xhtrdBYDQ1V0ND+XOWWVXtV4O0VekMXlbpb5mk9xQAEIuMgKg4iYyEy3nlubTr5W0+DTUNtuhSIn6uqsnV/LUu2l7F4aykfFVWjCv0So5kzuj9zxvTn3BFpxHdzk05rm4c9lfXscBPD9tJadpTWUlBeR6vH+R8JExiaGn9M09KoAQkMS0sgKiLsSPyFFfVeFX8F5e49bjP6xDBjuHO0f/bwVDKTe+Zkb72GqlMhH6nAq7qo2L3L3eXmzm80dUR41LEVdFScU3G3PzpW4J2Vdfoed5uIGOeIpBvZNNSmR2tobmNlwUEWby3j3W1l7K9x+kByM/tw54UjuTBnAOMykvw6P05EeBjD+zlH/XPHHy1vafNQeLCO7W6CcBJFLe9sLaPNTRARYUJWWjyDk2PZur+WA4ec+PsnRnOOV8U/JCXOxvafrtYmqDsI9Qfd50poqDx5xe5p6XqfYZEQm+w++kJSBvQfe2xZ++sY79dJEB4cgw98ZYnABERJdQPvbnMq/vd3HqSp1UNcVDjnjUzj7otGMXt0vx7RRh4ZHsZI9+jfW1NrGwXldU4Tk3sGsbeinilZyUcqfpsKuQvtR+r1B6Guwqtyr+ikzF0+0RF6dJJTabdX1v3Hdl2Je5dHxnX7UXew6jWJQFXtn64bdXeTYZtHyS+q5t1tpSzeWsa2A84/9pCUOK6ZNoQLx/RnWnYK0RHBMSladEQ4Y9KTGJOeFOhQAk/VORLvWIHXV3ReqdcfhNYuRr6FR0FcGsSnOs8p2ccux6VCfNrR1zF9ILzXVGMB0yt+gjExMVRUVJCammrJoBuoKhUVFcTEfLoj8pqGFpbvKOfdrWUs/aScyrpmwsOEvKHJfPeSHObkDGB4Pztq7rFUnSaY2hKoPQC1++HQfuf5yKPUqdi76gyNjD9aicf3d47WvSvzI8/uNtGJdpQeAL0iEWRmZlJcXEx5eXmgQ+k1YmJiyMzMPOX31Te38sbGA7z4UTGrCypp9Sh94yK5YHR/5uT0Z9bIfvSJ613tq0Gpqdap3A95VfJHHgecCv/wAWhrPv69camQmAGJA52r7uP7dV6px6c5HZ+mx+sViSAyMpLs7OxAhxGyVJX1e6t4bm0xr23Yz+GmVoamxrFw1jDm5PRn0pBkwoP0RihBp7XJrdg7VO6HvCr52v3QfPj490YlOpV7UjoMPdt53V7hJ6Y75QkDIMIubOttekUiMIFReqiRF9fv47l1RRSU1xEbGc6luel8YUom07JTrMmnO3janBEw9RXHdqh6t7/XV8DhMqeCr+/keszwqKOV+oBxMOIip1JPTD9ayScOdJplTEiyRGBOSXOrh8VbS3luXTFLt5fhUZialcyts4ZzSW56wKds6PGa6zupzL2X2yt793VDFcdP0eWKToK4FKcZps9gGDzNrdS9KvmkDGeEjCVlcwL2X2t8sqXkEM+tK+Llj/ZRVd/CgKRobj1/OAumZDKsX0Kgwwus1iao3A2VBVBXdnSc+zGVu7vcUt/5PiTcqxM1tUOnamqH12lOArAmGtNNLBGYLlXXN/NKfgnPrSti075DRIWHcfHYASzIy2TWyH6h1e7vaYOaIqjYCRW73Gf3UV3EcUftUQlHK/CE/tB/TIcK3XsoZIoz1t2O2k2AWCIwx2jzKMt3lPPcumL+vbmU5jYP4zKS+MHlY5k/cVDvnvpY1Wlr967k2yv9qt3HjqCJToLU4TB4Oky8DlJHOGPeEwY6FXxk4C+GM8ZXlggMALsP1vH8uiJeWLePA4caSY6L5NrpQ/hCXibjMvoEOrzu1VANlbuOP7KvKDj2CtbwaEgZBmkjYfRcp7Jvf8T3syN402tYIghhdU2t/Gvjfp5bW8SawirCBM4f1Y/vXz6WC8f0D5qrfDvV0uC023c8sq/cBXXe15sI9B3iVO6DZ7gV/XDnuU8mhAXxz8AYH1kiCDGqyprCKhatLeL1jfupb25jWFo83547misnZTKwTxA2aahC+TbYvRwKl0HJx057vne7fcIAp3IfPe/YI/vkLOt0NSHPEkGI2F/TwAvrinl+XTGFFfXER4VzeW4GX8jLZMrQ5OAa86/qHN3vXgaFy6FwxdGj/D6DnXb7SdcdPbpPGe7MGGmM6ZQlgl6spc3DW5sPsGhtMSt2lONRmJ6dwu1zRnLJWQP9dheubqfqDM0sXO4e9a9wpj8A5yKp4XMg6zzIPg/6DrW2e2NOUZDUBOZUVdY1c9vf1rF6dyUZfWL4+gUjWDAlk6Gp8YEOzTdVe7wq/uVwaJ9THt/fqfCzzoPsWU5nrlX8xnwqlgh6oU9Ka7n5L2s5cKiRXyzI5arJmT1/zH9NsXOk397OX73XKY9LhaxzIetup+JPG2UVvzHdzBJBL/PutlLu+Hs+sVHh/GPhDCYNSQ50SJ2rPXC00t+93BmnD86FVVnnwtm3O0f9/XIgLCygoRrT21ki6CVUlSeW7+Ynb2xlbHoSj9+QR0bfHjQF8OFyt2PXbe6p2OGUR/eBoefAtFucin/AeKv4jTnDLBH0Ak2tbfz3S5t4bl0x88YP5FdfnBD4juD6Sqepp73iL9/qlEclwJCzYfKXnYo/fYKN1TcmwCwRBLmKw03c+rd1rCms4o45I7jrolF+vcl7l1qbYO8qKFgCu5bA/o8Bde4LO2QG5H7RaeNPn9DrbvxtTLCzRBDEth04xH8+tZaDh5v47TWTuHxCxpn7cFUo2+JU+gVLYM8HzsyaYRGQORVmfweGnQ8ZkyGiF89PZEwvYIkgSL2zpZQ7n/2I+OgIFn31bCYM7uv/D609AAVL3cp/6dGx/KkjYdL1znj+oTPt4i1jgowlgiCjqvxxWQE/f3Mb4zP68PgNef6bFqK53jnSb2/uKdvslMemwLDZTsU/bDb0HeyfzzfGnBGWCIJIU2sb33lxIy+u38eluek8sGACsVHd2NHq8cCBj4829+xd5Uy9HB7ltPNf9AMYdgEMzLWRPcb0IpYIgkR5bRNffXot6/dWc/dFo7jjwhHdMz9QdZF7xP8uFLwHDZVOef9xMG0hDL8AhpwDUXGf/rOMMT2SJYIgsKXkELf8dS0VdU38/trJXJqbfvo7azzkDOvc9a6TACp2OuUJA2DkZ4429yQO6JbYjTE9nyWCHu6tzQe4+x/5JMVE8txXz+GszFO8SUxbK5Ssdyr+XUugeA1oG0TEQtZMyPsPp7mn/xibusGYEGWJoIdSVR5ZuotfvrWdCZlOp3D/pFPoFK47CCt+DeufhqYaQJwx/DPvdJp7Bk+3efiNMYAlgh6psaWNe1/YwMv5JVwxIYNfLMglJtLHTuGGalj5O1j1B2dc/7grIedSyD4f4lP9GrcxJjhZIuhhymobWfjXdeQXVfOtz4zi6xf42CncXAer/wjv/wYaq2Hs5+CC70K/0f4O2RgT5CwR9CCb9tVwy1/XUl3fwqPXT2bueB86hVubYN1TsOwBqCtzOnzn/LfTDGSMMT6wRNBDvLlpP3f/42OS4yJ5/razGZdxkk7htlb4+O/w3s+d+/MOPRe+9LQz3t8YY06BX68KEpG5IrJdRHaKyL0n2G6qiLSJyAJ/xtMTqSq/XbyDW/+2npz0RF6+feaJk4DHA5tegEemw6u3Q3wafPkluPE1SwLGmNPitzMCEQkHfg9cDBQDa0TkVVXd0sl2Pwfe8lcsPVVjSxvffn4Dr35cwucnDeKnV57VdaewKnzyFrz7IyjdCP3GwJeecTqCbdinMeZT8GfT0DRgp6oWAIjIs8B8YEuH7b4BvABM9WMsPU7poUYW/nUtG/bV8O25o7nt/OFddwrvXgaL/9e5BiA5G658HMZfZfP4G2O6hT8TwSCgyGu5GJjuvYGIDAI+D8zhBIlARBYCCwGGDBnS7YGeaRuLnU7hQ40t/PH6KXxm3MDONyxe6ySA3e9BYgZc/huYeJ3N52+M6Vb+TASdHd5qh+WHgHtUte1EQyRV9THgMYC8vLyO+wgq/9qwn28+l09qfDQv3HYOY9I7mbL5wCZY8mPY/jrEpcFnf+pcARzpp1lGjTEhzZ+JoBjwnp84EyjpsE0e8KybBNKAS0SkVVVf9mNcAaGq/GbxDh56Zwd5Q5N59MtTSEvocGVvxS5Y8hOnMzg6yRkGOv02iE4ITNDGmJDgz0SwBhgpItnAPuBq4FrvDVQ1u/21iDwFvNYbk0BDcxvfev5j/rVhP1dNzuQnV44nOsKrfb+m2BkG+tEzzrQP594N53wD4lICF7QxJmT4LRGoaquI3I4zGigceFJVN4vIre76R/312T3NwqfXsmLnQb57SQ63nDfsaKfw4TJY/iCs/ZOzPO0WOO+bkNA/cMEaY0KOXy8oU9XXgdc7lHWaAFT1Rn/GEijV9c0s33GQO+aMYOGs4U5hQxV88FtnPqDWJph4LZx/j93pyxgTEHZlsZ+t21MFwMwRadB0GFY/Ch88DI01zhDQ2d+FtBEBjtIYE8osEfjZ2j1VxIe3MHn/s/DCr6GuHEZfAhd8DwaOD3R4xhhjicDf1hVW8Xzsz4j891ZnKug5/wODQ+raOWNMD2eJwI+aWz0cKN7FmIitMPs7MLvL6ZaMMSZg/DrpXKjbVFLDJM9mZ2H0vMAGY4wxXbBE4EfrCquYEbYVT3QSDLD+AGNMz2SJwI/W7qnk3MjthA2daRPEGWN6LEsEfqKq7CncxWAtgayZgQ7HGGO6ZInAT/ZU1DOqYYOzkHVuYIMxxpgTsETgJ2v3VDE9bCttUYkwMDfQ4RhjTJcsEfjJuj2VnBOxlbAhZ1v/gDGmR7NE4Ce7CgrIpgTJtmYhY0zPdtJEICKXiYgljFNQXd9Mv8p1zsJQSwTGmJ7Nlwr+amCHiPxCRMb4O6DeYP3eKmaEbaEtIh7SJwQ6HGOMOaGTJgJVvR6YBOwC/iwiK0VkoYgk+j26ILXWvZCMITMg3GbxMMb0bD41+ajqIeAF4FkgHeeG8+tF5Bt+jC1ofVKwm5Fh+wi3/gFjTBDwpY/gchF5CXgXiASmqeo8YALwLT/HF3SaWz3E7V/lLGSdF9hgjDHGB760W3wB+LWqLvMuVNV6EfkP/4QVvDaX1DBZt9AaHkdExsRAh2OMMSflS9PQfcCH7QsiEisiWQCquthPcQWtdXuc/oG2zGkQHhnocIwx5qR8SQTPAR6v5Ta3zHRi665CcsKKiB5uzULGmODgSyKIUNXm9gX3dZT/QgpeqorsXeks2PxCxpgg4UsiKBeRK9oXRGQ+cNB/IQWvvZX1jGv+mNawGMiYHOhwjDHGJ750Ft8KPCMivwMEKAJu8GtUQWptYRXTw7bRlJ5HRISdNBljgsNJE4Gq7gJmiEgCIKpa6/+wgtPmXXv4fNheGHl9oEMxxhif+XTZq4hcCowDYkQEAFX9Xz/GFZTaClcQhoJdSGaMCSK+XFD2KPAl4Bs4TUNfAIb6Oa6gU1PfwuBDH9EaFg2DpgQ6HGOM8ZkvncXnqOoNQJWq3g+cDQz2b1jBx5lobit1/SZDRHSgwzHGGJ/5kgga3ed6EckAWoBs/4UUnDbu2sNY2UPcqFmBDsUYY06JL30E/xSRvsAvgfWAAo/7M6hg1LBzBWGihA23RGCMCS4nTATuDWkWq2o18IKIvAbEqGrNmQguWLS0eehXsYbW8CgiBuUFOhxjjDklJ2waUlUP8Cuv5SZLAsfbXHKIKWylJjUXImMCHY4xxpwSX/oI3haRq6R93Kg5zsc79zBedhMz4vxAh2KMMafMlz6C/wfEA60i0ogzhFRVNcmvkQWR2k9WEC5K/ChLBMaY4OPLlcV2S8oTUFWSSlfTKpFEZE4NdDjGGHPKTpoIRKTTYTAdb1TTxXvnAr8BwoEnVPVnHdbPB36IM811K3CXqq7wIe4eo6iygdzWTVSmjqd/VFygwzHGmFPmS9PQf3m9jgGmAeuAOSd6k4iEA78HLgaKgTUi8qqqbvHabDHwqqqqiOQCi4CcU4g/4PJ3FXGJ7KY6++uBDsUYY06LL01Dl3svi8hg4Bc+7HsasFNVC9z3PQvMB44kAlU97LV9PM41CkGlYusyIsRDytgLAx2KMcacFl9GDXVUDIz3YbtBOFNWe79vUMeNROTzIrIN+BfQ6T2QRWShiKwVkbXl5eWnEbL/xJasopVwwoZMC3QoxhhzWnzpI/gtR4/Uw4CJwMc+7Luz4abHHfGr6kvAS25fxA+BizrZ5jHgMYC8vLwec9ZQ09DCqIZ8yvqOIyMqPtDhGGPMafGlj2Ct1+tW4O+q+r4P7yvm2MnpMoGSrjZW1WUiMlxE0lQ1KO6All+wj3NkN6VDFgY6FGOMOW2+JILngUZVbQOnE1hE4lS1/iTvWwOMFJFsYB9wNXCt9wYiMgLY5XYWT8a5F3LFqX6JQCnbtIxIaSNt/An7zY0xpkfzpY9gMRDrtRwLvHOyN6lqK3A78BawFVikqptF5FYRudXd7Cpgk4jk44ww+pKq9pimn5OJKHqfNsKIyT4n0KEYY8xp8+WMIMZ7dI+qHhYRnwbMq+rrwOsdyh71ev1z4Oc+xtqjtLR5GFL7EfsTxpAZnRDocIwx5rT5ckZQ5zbbACAiU4AG/4UUHLbuLeUsdtI4yM4GjDHBzZczgruA50SkvaM3HefWlSGteON75EobqeMuCHQoxhjzqfhyQdkaEckBRuMMCd2mqi1+j6ynK1xBG2Ekjz4v0JEYY8yn4svN678OxKvqJlXdCCSIyNf8H1rPpaqkV62lOGYUxNgkrMaY4OZLH8Et7h3KAFDVKuAWv0UUBPaVVzLWs4PDA6cHOhRjjPnUfEkEYd43pXEnk4vyX0g93+78pURLK0k51j9gjAl+vnQWvwUsEpFHcaaIuBV4w69R9XDNu5bTpkJGriUCY0zw8yUR3AMsBG7D6Sz+CGfkUMhKq1jL3qgRZMf1DXQoxhjzqZ20aci9gf0qoADIAy7EuVI4JNXU1pLTso2q/jbbqDGmd+jyjEBERuHMD3QNzvw//wBQ1ZBuDynIf49J0kLsiE5v3GaMMUHnRE1D24DlwOWquhNARO4+I1H1YPWfvIdHhaGTj5st2xhjgtKJmoauAg4AS0TkcRG5kM7vMRBS+pR+yO6IbOL6pAU6FGOM6RZdJgJVfUlVv4RzD+GlwN3AABH5g4h85gzF16O0NDUwvGkL5Sl5gQ7FGGO6jS+dxXWq+oyqXoZzc5l84F5/B9YT7dm4glhpJny4TSthjOk9Tumexapaqap/VNWQvBNLzdYlAAyZaP0Dxpje43RuXh+y4vavZodkMWBgRqBDMcaYbmOJwEfa2kxW/UZK+k4++cbGGBNELBH4qGz7KmJpgiEzAx2KMcZ0K0sEPjq4aTEAA3MvDHAkxhjTvSwR+Ciy+AN26GBGZGcFOhRjjOlWlgh80dZCZu1GChMnER4W8tfUGWN6GUsEPqjbs444GmjOtBvVG2N6H0sEPijd4PQP9LMb1RtjeiFLBD6QwhXs0EGMGzUi0KEYY0y3s0RwMm2tDKjJZ0dMLvHRvtzHxxhjgoslgpNoLfmYOK2nLv3sQIdijDF+YYngJMo3Ov0DfcbMDmwgxhjjJ5YITqKlYDm7POmclTMq0KEYY4xfWCI4EU8b/SrXsTHyLNL7xAY6GmOM8QtLBCegBzYQ66mjxm5Ub4zpxSwRnEDN1qUAxI2yG9UbY3ovGw95Ag073qPKM4Cxo3MCHYoxxviNnRF0xeOhT/la1ss4cgYmBToaY4zxG0sEXSndRFxbLWWpeTbRnDGmV/NrIhCRuSKyXUR2ishxN7wXketEZIP7+EBEJvgznlPRuHMZAJF2o3pjTC/ntz4CEQkHfg9cDBQDa0TkVVXd4rXZbuB8Va0SkXnAY8B0f8V0Kg5vf49ST39yRo0NdCjGGONX/jwjmAbsVNUCVW0GngXme2+gqh+oapW7uArI9GM8vvN4iD+wmg91DBOH9A10NMYY41f+TASDgCKv5WK3rCv/CbzR2QoRWSgia0VkbXl5eTeG2IXyrcS21lCUNJkEm2jOGNPL+TMRdNbDqp1uKHIBTiK4p7P1qvqYquapal6/fv26McTOtRUsd+IaajeqN8b0fv483C0GBnstZwIlHTcSkVzgCWCeqlb4MR6fHf5kKbWaxvDR4wIdijHG+J0/zwjWACNFJFtEooCrgVe9NxCRIcCLwJdV9RM/xuI7VaKLV7HKM5a8ocmBjsYYY/zOb2cEqtoqIrcDbwHhwJOqullEbnXXPwp8H0gFHhERgFZVzfNXTD4p30ZMSxXbo89iQV+baM4Y0/v5tSdUVV8HXu9Q9qjX65uBm/0ZwykrXAFAy+BzAxyIMcacGTYkpoP6He9RpalkjxgT6FCMMeaMsCkmvKkStvcDVnvGMCUrJdDRGGPMGWGJwNvBHcQ0VbgTzSUGOhpjjDkjLBF4K3SuH6jPmE5EuP1ojDGhwfoIvLQUrOCgppA5bHygQzHGmDPGDnvbqaK7l7Pak0Oe9Q8YY0KIJYJ2FbuIaiznQ88YJtlEc8aYEGKJoN0e5/qBstRpJMZEBjgYY4w5c6yPwOXZvZwK7Ut6ts0vZIwJLXZGAKBK2+4VrPSMIS/b+geMMaHFEgFAZQGRdQecC8lsojljTIixRACw530AdsVNZJBNNGeMCTGWCAAK36eSPqRmjcedBdUYY0KGJQJVWncv54M2u37AGBOaLBFU7yGidp97IxpLBMaY0GOJoNDpH9gQPo4x6TbRnDEm9FgiKFxBjSSRkDneJpozxoSkkK/5PIUr+KDV+geMMaErtBNB9V7Cavayym5EY4wJYaGdCNz+gdVqE80ZY0JXaCeCPSuoDUtE+o0hySaaM8aEqJBOBFq4gg/bcpiSnRroUIwxJmBCNxHUFCNVhaxozbHrB4wxIS10E0F7/4BNNGeMCXGhmwj2rKAuLJHKhJFkJttEc8aY0BW6iaDwfdaTw5SsNJtozhgT0kIzERzaD5W7WNo0ypqFjDEhLzQTgXv/gVWeseRlWSIwxoS20EwEhctpDE+gMGIYY9KTAh2NMcYEVIgmgvfZEDaG3MEpRNpEc8aYEBd6tWBtKVTsYHHDKGsWMsYYQjER7FkBwMq2HOsoNsYYQjERFL5PU3g8W8hisiUCY4wJxUSwgm2RYxkxoK9NNGeMMfg5EYjIXBHZLiI7ReTeTtbniMhKEWkSkW/5MxYADpfDwe2802DXDxhjTDu/JQIRCQd+D8wDxgLXiMjYDptVAncAD/grjmO41w8sbx5tHcXGGOPy5xnBNGCnqhaoajPwLDDfewNVLVPVNUCLH+M4qnAFLeGxbNIsm3HUGGNc/kwEg4Air+Vit+yUichCEVkrImvLy8tPP6I977MzZjwpifE20Zwxxrj8mQg6m8lNT2dHqvqYquapal6/fv1OL5q6CijbwntNTrOQTTRnjDEOfyaCYmCw13ImUOLHzzsxt3/g7boRTLFmIWOMOcKfiWANMFJEskUkCrgaeNWPn3diGRPZnPsdNuow8mzEkDHGHBHhrx2raquI3A68BYQDT6rqZhG51V3/qIgMBNYCSYBHRO4CxqrqoW4PqO8Qnou4nIjIIsZm2ERzxhjTzm+JAEBVXwde71D2qNfrAzhNRmfEuj1VTBjcxyaaM8YYLyFTI9Y1tbJl/yEbNmqMMR2ETCL4uKiaNo8yxS4kM8aYY4RMIoiMCOOC0f2YPMQSgTHGePNrH0FPMjUrhT/fNC3QYRhjTI8TMmcExhhjOmeJwBhjQpwlAmOMCXGWCIwxJsRZIjDGmBBnicAYY0KcJQJjjAlxlgiMMSbEiepp3SsmYESkHNhzmm9PAw52YzjBwL5zaLDvHBo+zXceqqqd3tkr6BLBpyEia1U1L9BxnEn2nUODfefQ4K/vbE1DxhgT4iwRGGNMiAu1RPBYoAMIAPvOocG+c2jwy3cOqT4CY4wxxwu1MwJjjDEdWCIwxpgQFzKJQETmish2EdkpIvcGOh5/E5HBIrJERLaKyGYRuTPQMZ0JIhIuIh+JyGuBjuVMEZG+IvK8iGxzf99nBzomfxKRu92/6U0i8ncRiQl0TP4gIk+KSJmIbPIqSxGRf4vIDve5W265GBKJQETCgd8D84CxwDUiMjawUfldK/BNVR0DzAC+HgLfGeBOYGuggzjDfgO8qao5wAR68fcXkUHAHUCeqo4HwoGrAxuV3zwFzO1Qdi+wWFVHAovd5U8tJBIBMA3YqaoFqtoMPAvMD3BMfqWq+1V1vfu6FqdyGBTYqPxLRDKBS4EnAh3LmSIiScAs4E8AqtqsqtUBDcr/IoBYEYkA4oCSAMfjF6q6DKjsUDwf+Iv7+i/A57rjs0IlEQwCiryWi+nllaI3EckCJgGrAxyKvz0EfBvwBDiOM2kYUA782W0Se0JE4gMdlL+o6j7gAWAvsB+oUdW3AxvVGTVAVfeDc7AH9O+OnYZKIpBOykJi3KyIJAAvAHep6qFAx+MvInIZUKaq6wIdyxkWAUwG/qCqk4A6uqm5oCdy28TnA9lABhAvItcHNqrgFyqJoBgY7LWcSS89nfQmIpE4SeAZVX0x0PH42UzgChEpxGn6myMifwtsSGdEMVCsqu1ne8/jJIbe6iJgt6qWq2oL8CJwToBjOpNKRSQdwH0u646dhkoiWAOMFJFsEYnC6Vx6NcAx+ZWICE678VZVfTDQ8fibqn5HVTNVNQvn9/uuqvb6I0VVPQAUichot+hCYEsAQ/K3vcAMEYlz/8YvpBd3jnfiVeAr7uuvAK90x04jumMnPZ2qtorI7cBbOKMMnlTVzQEOy99mAl8GNopIvlv2XVV9PXAhGT/5BvCMe5BTANwU4Hj8RlVXi8jzwHqckXEf0UunmhCRvwOzgTQRKQbuA34GLBKR/8RJil/ols+yKSaMMSa0hUrTkDHGmC5YIjDGmBBnicAYY0KcJQJjjAlxlgiMMSbEWSIwxiUibSKS7/Xotit0RSTLexZJY3qSkLiOwBgfNajqxEAHYcyZZmcExpyEiBSKyM9F5EP3McItHyoii0Vkg/s8xC0fICIvicjH7qN9CoRwEXncnUv/bRGJdbe/Q0S2uPt5NkBf04QwSwTGHBXboWnoS17rDqnqNOB3OLOc4r7+q6rmAs8AD7vlDwPvqeoEnHl/2q9iHwn8XlXHAdXAVW75vcAkdz+3+uerGdM1u7LYGJeIHFbVhE7KC4E5qlrgTuR3QFVTReQgkK6qLW75flVNE5FyIFNVm7z2kQX8272hCCJyDxCpqj8SkTeBw8DLwMuqetjPX9WYY9gZgTG+0S5ed7VNZ5q8XrdxtI/uUpw76E0B1rk3XDHmjLFEYIxvvuT1vNJ9/QFHb5N4HbDCfb0YuA2O3EM5qaudikgYMFhVl+DcVKcvcNxZiTH+ZEcexhwV6zVTKzj3AW4fQhotIqtxDp6uccvuAJ4Ukf/CuUtY+6yfdwKPuTNEtuEkhf1dfGY48DcR6YNzA6Vfh8CtJk0PY30ExpyE20eQp6oHAx2LMf5gTUPGGBPi7IzAGGNCnJ0RGGNMiLNEYIwxIc4SgTHGhDhLBMYYE+IsERhjTIj7/zFU1SEhD0AUAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#######################################################################\n",
    "# Your Code here\n",
    "#######################################################################\n",
    "\n",
    "plt.plot(train_acc_history_SGD, label='training')\n",
    "plt.plot(val_acc_history_SGD, label='validation')\n",
    "plt.title('SGD Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.plot(train_acc_history_SGD_Momentum, label='training')\n",
    "plt.plot(val_acc_history_SGD_Momentum, label='validation')\n",
    "plt.title('SGD Momentum Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "#######################################################################\n",
    "#                         END OF YOUR CODE                            #\n",
    "#######################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GVcoULZa5seR"
   },
   "source": [
    "Report your obervation here:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qxOkNE5IE76I"
   },
   "source": [
    "# 4.2(g) Adding L2 regularization (EECS 504 Only)\n",
    "\n",
    "Add L2 regularization to the softmax classifier in 4.2(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e3VuqVbKh6VB"
   },
   "source": [
    "# 4.2(h) Training with L2 regularization (EECS 504 Only)\n",
    "\n",
    "Train the model again using L2 regularization, using SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "id": "tQoj9kabUBy8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Iteration 1 / 25000) loss: 2.302056\n",
      "(Epoch 0 / 10) train acc: 0.129000; val_acc: 0.111800\n",
      "(Iteration 1001 / 25000) loss: 2.032334\n",
      "(Iteration 2001 / 25000) loss: 1.694781\n",
      "(Epoch 1 / 10) train acc: 0.370000; val_acc: 0.344100\n",
      "(Iteration 3001 / 25000) loss: 2.000996\n",
      "(Iteration 4001 / 25000) loss: 2.035500\n",
      "(Epoch 2 / 10) train acc: 0.382000; val_acc: 0.376300\n",
      "(Iteration 5001 / 25000) loss: 1.755034\n",
      "(Iteration 6001 / 25000) loss: 1.821312\n",
      "(Iteration 7001 / 25000) loss: 1.913979\n",
      "(Epoch 3 / 10) train acc: 0.396000; val_acc: 0.400600\n",
      "(Iteration 8001 / 25000) loss: 1.572111\n",
      "(Iteration 9001 / 25000) loss: 1.660214\n",
      "(Epoch 4 / 10) train acc: 0.435000; val_acc: 0.417700\n",
      "(Iteration 10001 / 25000) loss: 1.283392\n",
      "(Iteration 11001 / 25000) loss: 1.279843\n",
      "(Iteration 12001 / 25000) loss: 1.689852\n",
      "(Epoch 5 / 10) train acc: 0.434000; val_acc: 0.427200\n",
      "(Iteration 13001 / 25000) loss: 1.460471\n",
      "(Iteration 14001 / 25000) loss: 1.629298\n",
      "(Epoch 6 / 10) train acc: 0.430000; val_acc: 0.434900\n",
      "(Iteration 15001 / 25000) loss: 1.260379\n",
      "(Iteration 16001 / 25000) loss: 1.230441\n",
      "(Iteration 17001 / 25000) loss: 1.687735\n",
      "(Epoch 7 / 10) train acc: 0.476000; val_acc: 0.441700\n",
      "(Iteration 18001 / 25000) loss: 1.755300\n",
      "(Iteration 19001 / 25000) loss: 1.434907\n",
      "(Epoch 8 / 10) train acc: 0.455000; val_acc: 0.445600\n",
      "(Iteration 20001 / 25000) loss: 1.503139\n",
      "(Iteration 21001 / 25000) loss: 1.067568\n",
      "(Iteration 22001 / 25000) loss: 1.072492\n",
      "(Epoch 9 / 10) train acc: 0.473000; val_acc: 0.452500\n",
      "(Iteration 23001 / 25000) loss: 1.897846\n",
      "(Iteration 24001 / 25000) loss: 1.308194\n",
      "(Epoch 10 / 10) train acc: 0.518000; val_acc: 0.455500\n"
     ]
    }
   ],
   "source": [
    "# initialize model (remember to set the l2 regularization weight > 0)\n",
    "model_SGD_L2 = SoftmaxClassifier(hidden_dim = 300, weight_scale=1e-2, reg=0.01)\n",
    "\n",
    "# start training using SGD. The training hyperparameter you choose should be same to the 4.2(c)\n",
    "model_SGD_L2, train_acc_history_SGD_L2, val_acc_history_SGD_L2 = trainNetwork(\n",
    "    model_SGD_L2, train_data, \n",
    "    learning_rate = learning_rate_SGD,\n",
    "    lr_decay=lr_decay_SGD, \n",
    "    batch_size=batch_size_SGD,\n",
    "    num_epochs=10, \n",
    "    print_every=1000, optimizer = 'SGD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "id": "R5yYAg3mWFX5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy of model_SGD_L2: 0.4648\n"
     ]
    }
   ],
   "source": [
    "# report test accuracy\n",
    "acc = testNetwork(model_SGD_L2, data['X_test'], data['y_test'])\n",
    "print(\"Test accuracy of model_SGD_L2: {}\".format(acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9AuWH2_Aj2Ac"
   },
   "source": [
    "# 4.2(i) Plot\n",
    "\n",
    "Using the train_acc_history and val_acc_history, plot the train & val accuracy versus epochs on one plot for model with and without L2 regularization, using SGD as optimizer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "id": "eG7H8nXCgudY"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#######################################################################\n",
    "# TODO: Your Code here\n",
    "#######################################################################\n",
    "plt.plot(train_acc_history_SGD_L2, label='training')\n",
    "plt.plot(val_acc_history_SGD_L2, label='validation')\n",
    "plt.title('SGD Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "#######################################################################\n",
    "#                         END OF YOUR CODE                            #\n",
    "#######################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MbrfhTzdlyRz"
   },
   "source": [
    "# 4.2(j) Tune your own model\n",
    "\n",
    "Feel free to tune any hyperparameters and choose any optimizer as you want -- just train the best model you can!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "id": "SrjE2jyKmY-9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Iteration 1 / 50000) loss: 2.285836\n",
      "(Epoch 0 / 20) train acc: 0.140000; val_acc: 0.131200\n",
      "(Iteration 1001 / 50000) loss: 1.692356\n",
      "(Iteration 2001 / 50000) loss: 1.717788\n",
      "(Epoch 1 / 20) train acc: 0.405000; val_acc: 0.377800\n",
      "(Iteration 3001 / 50000) loss: 1.482898\n",
      "(Iteration 4001 / 50000) loss: 1.256890\n",
      "(Epoch 2 / 20) train acc: 0.426000; val_acc: 0.422100\n",
      "(Iteration 5001 / 50000) loss: 1.913611\n",
      "(Iteration 6001 / 50000) loss: 1.828768\n",
      "(Iteration 7001 / 50000) loss: 1.425368\n",
      "(Epoch 3 / 20) train acc: 0.497000; val_acc: 0.441900\n",
      "(Iteration 8001 / 50000) loss: 1.116475\n",
      "(Iteration 9001 / 50000) loss: 1.329572\n",
      "(Epoch 4 / 20) train acc: 0.492000; val_acc: 0.457400\n",
      "(Iteration 10001 / 50000) loss: 1.564591\n",
      "(Iteration 11001 / 50000) loss: 1.405186\n",
      "(Iteration 12001 / 50000) loss: 1.738024\n",
      "(Epoch 5 / 20) train acc: 0.512000; val_acc: 0.468700\n",
      "(Iteration 13001 / 50000) loss: 1.493571\n",
      "(Iteration 14001 / 50000) loss: 1.032437\n",
      "(Epoch 6 / 20) train acc: 0.522000; val_acc: 0.477300\n",
      "(Iteration 15001 / 50000) loss: 1.178130\n",
      "(Iteration 16001 / 50000) loss: 1.395846\n",
      "(Iteration 17001 / 50000) loss: 1.098091\n",
      "(Epoch 7 / 20) train acc: 0.520000; val_acc: 0.483900\n",
      "(Iteration 18001 / 50000) loss: 1.143717\n",
      "(Iteration 19001 / 50000) loss: 1.294971\n",
      "(Epoch 8 / 20) train acc: 0.543000; val_acc: 0.488000\n",
      "(Iteration 20001 / 50000) loss: 1.058635\n",
      "(Iteration 21001 / 50000) loss: 1.060776\n",
      "(Iteration 22001 / 50000) loss: 1.454113\n",
      "(Epoch 9 / 20) train acc: 0.537000; val_acc: 0.495500\n",
      "(Iteration 23001 / 50000) loss: 1.164303\n",
      "(Iteration 24001 / 50000) loss: 1.394336\n",
      "(Epoch 10 / 20) train acc: 0.543000; val_acc: 0.496200\n",
      "(Iteration 25001 / 50000) loss: 1.353889\n",
      "(Iteration 26001 / 50000) loss: 0.877718\n",
      "(Iteration 27001 / 50000) loss: 1.006404\n",
      "(Epoch 11 / 20) train acc: 0.605000; val_acc: 0.498900\n",
      "(Iteration 28001 / 50000) loss: 1.433386\n",
      "(Iteration 29001 / 50000) loss: 1.809309\n",
      "(Epoch 12 / 20) train acc: 0.558000; val_acc: 0.501500\n",
      "(Iteration 30001 / 50000) loss: 1.092809\n",
      "(Iteration 31001 / 50000) loss: 0.963861\n",
      "(Iteration 32001 / 50000) loss: 1.464629\n",
      "(Epoch 13 / 20) train acc: 0.574000; val_acc: 0.502200\n",
      "(Iteration 33001 / 50000) loss: 1.143395\n",
      "(Iteration 34001 / 50000) loss: 1.062914\n",
      "(Epoch 14 / 20) train acc: 0.586000; val_acc: 0.505900\n",
      "(Iteration 35001 / 50000) loss: 1.380557\n",
      "(Iteration 36001 / 50000) loss: 1.180371\n",
      "(Iteration 37001 / 50000) loss: 1.217352\n",
      "(Epoch 15 / 20) train acc: 0.545000; val_acc: 0.503000\n",
      "(Iteration 38001 / 50000) loss: 1.525390\n",
      "(Iteration 39001 / 50000) loss: 1.279228\n",
      "(Epoch 16 / 20) train acc: 0.606000; val_acc: 0.507500\n",
      "(Iteration 40001 / 50000) loss: 1.560260\n",
      "(Iteration 41001 / 50000) loss: 0.633237\n",
      "(Iteration 42001 / 50000) loss: 1.119924\n",
      "(Epoch 17 / 20) train acc: 0.593000; val_acc: 0.509100\n",
      "(Iteration 43001 / 50000) loss: 1.125946\n",
      "(Iteration 44001 / 50000) loss: 1.434331\n",
      "(Epoch 18 / 20) train acc: 0.601000; val_acc: 0.511000\n",
      "(Iteration 45001 / 50000) loss: 1.339493\n",
      "(Iteration 46001 / 50000) loss: 1.495159\n",
      "(Iteration 47001 / 50000) loss: 1.390175\n",
      "(Epoch 19 / 20) train acc: 0.597000; val_acc: 0.515100\n",
      "(Iteration 48001 / 50000) loss: 1.516789\n",
      "(Iteration 49001 / 50000) loss: 1.195281\n",
      "(Epoch 20 / 20) train acc: 0.623000; val_acc: 0.514100\n"
     ]
    }
   ],
   "source": [
    "#######################################################################\n",
    "# TODO: Train your own model                                          #\n",
    "#######################################################################\n",
    "\n",
    "# initialize model (set reg=0.0 for EECS 442 students)\n",
    "your_model = SoftmaxClassifier(hidden_dim = 300, weight_scale=1e-2,  reg= 0.01)\n",
    "\n",
    "# train your moodel\n",
    "your_model, train_acc_history_your_model, val_acc_history_your_model = trainNetwork(\n",
    "    your_model, train_data, \n",
    "    learning_rate = 1e-3 ,\n",
    "    lr_decay=  0.9 , \n",
    "    batch_size= 16 ,\n",
    "    num_epochs= 20 , \n",
    "    print_every=1000, optimizer = 'SGD_Momentum')\n",
    "#######################################################################\n",
    "#                         END OF YOUR CODE                            #\n",
    "#######################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "id": "vI4SK0PPmbrE"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy of your model: 0.511\n"
     ]
    }
   ],
   "source": [
    "# report test accuracy \n",
    "# (Run this code only once when you obtain the highest model in validation set!)\n",
    "acc = testNetwork(your_model, data['X_test'], data['y_test'])\n",
    "print(\"Test accuracy of your model: {}\".format(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
